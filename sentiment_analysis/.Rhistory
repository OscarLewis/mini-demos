install.packages('syuzhet')
#  install.packages('syuzhet')
library(syuzhet)
# Create a vector of emotional sentences.
# Add some happy ones, angry ones - you name it!
student_sentences <- c('I really like the pie you gave me this morning.',
'Your shoes suck and are just plain ugly.',
'I\'d really truly love going out in this weather!',
"I\m so glad we're here today",
"Andrew and Michelle\'s presentation was so good"
)
# Create a vector of emotional sentences.
# Add some happy ones, angry ones - you name it!
student_sentences <- c('I really like the pie you gave me this morning.',
'Your shoes suck and are just plain ugly.',
'I\'d really truly love going out in this weather!',
"I\m so glad we're here today",
"Andrew and Michelle\'s presentation was so good"
)
# Create a vector of emotional sentences.
# Add some happy ones, angry ones - you name it!
student_sentences <- c('I really like the pie you gave me this morning.',
'Your shoes suck and are just plain ugly.',
'I\'d really truly love going out in this weather!',
"I\m so glad we're here today",
"Andrew and Michelle\'s presentation was so good"
)
# Create a vector of emotional sentences.
# Add some happy ones, angry ones - you name it!
student_sentences <- c('I really like the pie you gave me this morning.',
'Your shoes suck and are just plain ugly.',
'I\'d really truly love going out in this weather!',
"I\m so glad we're here today",
"Andrew and Michelle\'s presentation was so good")
# Create a vector of emotional sentences.
# Add some happy ones, angry ones - you name it!
student_sentences <- c('I really like the pie you gave me this morning.',
'Your shoes suck and are just plain ugly.',
'I\'d really truly love going out in this weather!',
"I'm so glad we're here today",
"Andrew and Michelle\'s presentation was so good")
# Analyze sentiment for student sentences
student_sentiments <- data.frame(get_sentiment(student_sentences))
student_analysis <- cbind(student_sentences, student_sentiments)
View(student_analysis)
library(dplyr)
library(stringr)
library(tidytext)
library(tidyr)
library(ggplot2)
# install.packages('dplyr')
# install.packages('stringr')
install.packages('tidytext')
library(dplyr)
library(stringr)
library(tidytext)
library(tidyr)
##### LEXICONS #####
# Use the get_sentiments() function to get your dictionary of positive
# and negative words. Use the lexicon which categorizes words into
# positive and negative.
bing_sentiments <- get_sentiments("bing")
setwd("C:/Users/Oscar/Desktop/School/info201/mini-demos/sentiment_analysis")
##### DATA ANALYSIS + WRANGLING #####
# Read books data in
books <- read.csv(".data/austen_books.csv", stringsAsFactors = FALSE)
##### DATA ANALYSIS + WRANGLING #####
# Read books data in
books <- read.csv(".data/austen_books.csv", stringsAsFactors = FALSE)
##### DATA ANALYSIS + WRANGLING #####
# Read books data in
books <- read.csv("./data/austen_books.csv", stringsAsFactors = FALSE)
# Map each word in the 'books' dataset to its dictionary-prescribed sentiment.
jane_austen_sentiment <- books %>%
inner_join(bing_sentiments, by = "word")
# Instead of having each individual word, count the number of positive/negative
# words in each chapter.
jane_austen_sentiment <- jane_austen_sentiment %>%
count(book, chapter, sentiment)
View(jane_austen_sentiment)
# A chapter's overarching feeling will be calculated by the number of positive
# words minus the number of negative words. Create a new column called
# 'sentiment' with this value.
jane_austen_sentiment <- jane_austen_sentiment %>%
spread(sentiment, n, fill = 0)
# A chapter's overarching feeling will be calculated by the number of positive
# words minus the number of negative words. Create a new column called
# 'sentiment' with this value.
jane_austen_sentiment <- jane_austen_sentiment %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
# Instead of having each individual word, count the number of positive/negative
# words in each chapter.
jane_austen_sentiment <- jane_austen_sentiment %>%
count(book, chapter, sentiment)
# A chapter's overarching feeling will be calculated by the number of positive
# words minus the number of negative words. Create a new column called
# 'sentiment' with this value.
jane_austen_sentiment <- jane_austen_sentiment %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
# Instead of having each individual word, count the number of positive/negative
# words in each chapter.
jane_austen_sentiment <- jane_austen_sentiment %>%
count(book, chapter, sentiment)
# Instead of having each individual word, count the number of positive/negative
# words in each chapter.
jane_austen_sentiment <- jane_austen_sentiment %>%
count(book, chapter, sentiment)
# Map each word in the 'books' dataset to its dictionary-prescribed sentiment.
jane_austen_sentiment <- books %>%
inner_join(bing_sentiments, by = "word")
# Instead of having each individual word, count the number of positive/negative
# words in each chapter.
jane_austen_sentiment <- jane_austen_sentiment %>%
count(book, chapter, sentiment)
# A chapter's overarching feeling will be calculated by the number of positive
# words minus the number of negative words. Create a new column called
# 'sentiment' with this value.
jane_austen_sentiment <- jane_austen_sentiment %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
##### CREATE OUR VISUALIZATION #####
# Use ggplot to plot each chapter's sentiment by book.
ggplot(jane_austen_sentiment, aes(chapter, sentiment, fill = book)) +
geom_col(show.legend = F) +
facet_wrap(~book, ncol = 2, scales = "freex")
##### CREATE OUR VISUALIZATION #####
# Use ggplot to plot each chapter's sentiment by book.
ggplot(jane_austen_sentiment, aes(chapter, sentiment, fill = book)) +
geom_col(show.legend = F) +
facet_wrap(~book, ncol = 2, scales = "free_x")
#load library
library(class) #Has the knn function
#loading data
data("iris")
#load library
library(class) #Has the knn function
#loading data
data("iris")
#Set the seed for reproducibility
set.seed(4948493)
ir_sample <- sample(1:nrow(iris),size=nrow(iris)*.7)
ir_train <- iris[ir_sample,] #Select the 70% of rows
ir_test <- iris[-ir_sample,] #Select the 30% of rows
accuracy = function(actual, predicted) {
mean(actual == predicted)
}
pred <- knn(train = scale(ir_train[,-5]),
test = scale(ir_test[,-5]),
cl = ir_train$Species,
k = 40)
accuracy(ir_test$Species, pred)
pred <- knn(train = scale(ir_train[,-5]),
test = scale(ir_test[,-5]),
cl = ir_train$Species,
k = 5)
k_to_try = 1:100
acc_k = rep(x = 0, times = length(k_to_try))
for(i in seq_along(k_to_try)) {
pred <- knn(train = scale(ir_train[,-5]),
test = scale(ir_test[,-5]),
cl = ir_train$Species,
k = k_to_try[i])
acc_k[i] <- accuracy(ir_test$Species, pred)
}
plot(acc_k, type = "b", col = "dodgerblue", cex = 1, pch = 20,
xlab = "k, number of neighbors", ylab = "classification accuracy",
main = "Accuracy vs Neighbors")
# add lines indicating k with best accuracy
abline(v = which(acc_k == max(acc_k)), col = "darkorange", lwd = 1.5)
# add line for max accuracy seen
abline(h = max(acc_k), col = "grey", lty = 2)
